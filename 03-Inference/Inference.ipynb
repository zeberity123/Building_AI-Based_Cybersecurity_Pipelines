{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b52ab402-423b-47af-aa4a-61bec93d69c9",
   "metadata": {},
   "source": [
    "![DLI Header](../images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb0f43-4901-46d8-97b7-1b90fe721ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Inference in Morpheus Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0856b1-c23d-4cfc-9a97-5fe42db6cd66",
   "metadata": {},
   "source": [
    "The ability to perform inference on data is one of the key features of Morpheus. In this notebook you are going to begin performing very basic inference in your Morpheus pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6985fde-4a2f-40eb-b3da-10eb80b406f4",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006edff7-136e-4b4b-a2aa-26ef979ae41c",
   "metadata": {},
   "source": [
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- Perform very basic inference in Morpheus pipelines.\n",
    "- Utilize the `preprocessing` stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7df70-8912-40aa-a07f-c74235f322cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6bcc70-f6e4-44ce-990c-fd5a7aef0ce0",
   "metadata": {},
   "source": [
    "## Inference as a Pipeline Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851b813-f77b-4093-ad2e-eadce353a867",
   "metadata": {},
   "source": [
    "Inference is the process of passing live data to an already-trained machine or deep learning model. In the context of Morpheus, we are going to be able to send massive amounts of data to AI/ML/DL models to assist us in our cybersecurity goals.\n",
    "\n",
    "As you might guess, inference in Morpheus is performed as a stage in a pipeline. Each of the 3 Morpheus pipelines (`pipeline-fil`, `pipeline-ae`, and `pipeline-nlp`) provide their own inference capabilities, and in this workshop you are going to have the chance to work with them all.\n",
    "\n",
    "We are going to start working with `pipeline-fil`. Here we can see we have several options for inference stages in the FIL pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd9d616-ddd8-4ffd-82e0-89ca5bae9f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inf-identity  Perform a no-op inference for testing\n",
      "  inf-pytorch   Perform inference with PyTorch\n",
      "  inf-triton    Perform inference with Triton\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil --help | grep '  inf-'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf6e34d-0a37-4f79-af5f-63922cbffd09",
   "metadata": {},
   "source": [
    "Later we will be using both PyTorch and Triton as backends to perform inference, but to begin learning how to add inference, we will utilize `inf-identity` which as described above will simply perform a no-op inference for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b41b80-5bd1-4a52-a9d8-6e4cd875a7b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2c0f8-c82d-4e06-a8e4-ff111cc4263f",
   "metadata": {},
   "source": [
    "## Identity Pipeline (review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87979793-931b-44b5-ac20-e45b214eb172",
   "metadata": {},
   "source": [
    "For reference, here is the inference pipeline we left off with in the previous section:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34bb0c-7ae3-4b81-b11c-b3e1dcaca233",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed392a-fb4b-44a6-9050-467efbbd7636",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abcee0-b2ab-4ece-974b-52eb1ffe20f0",
   "metadata": {},
   "source": [
    "## Adding Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6975dd-cd85-42c1-b9ff-fbe65fc08762",
   "metadata": {},
   "source": [
    "Let's begin by adding an `inf-identity` stage to our existing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f85dff6-08cb-4975-9a69-8340bc0f655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/morpheus/bin/morpheus\", line 11, in <module>\n",
      "    sys.exit(run_cli())\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/cli.py\", line 1395, in run_cli\n",
      "    cli(obj={}, auto_envvar_prefix='MORPHEUS', show_default=True, prog_name=\"morpheus\")\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1689, in invoke\n",
      "    return _process_result(rv)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1626, in _process_result\n",
      "    value = ctx.invoke(self._result_callback, value, **ctx.params)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/decorators.py\", line 26, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/cli.py\", line 557, in post_pipeline\n",
      "    pipeline.run()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 1239, in run\n",
      "    asyncio.run(self._do_run())\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/asyncio/base_events.py\", line 616, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 1214, in _do_run\n",
      "    self.build_and_start()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 1038, in build_and_start\n",
      "    self.start()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 998, in start\n",
      "    self._neo_executor.start()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 960, in inner_build\n",
      "    s.build(seg)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 526, in build\n",
      "    dep.build(seg, do_propagate=do_propagate)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 526, in build\n",
      "    dep.build(seg, do_propagate=do_propagate)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 502, in build\n",
      "    in_ports_pairs = self._pre_build()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 765, in _pre_build\n",
      "    raise RuntimeError(\"The {} stage cannot handle input of {}. Accepted input types: {}\".format(\n",
      "RuntimeError: The inference stage cannot handle input of <class 'morpheus.pipeline.messages.MultiMessage'>. Accepted input types: (<class 'morpheus.pipeline.messages.MultiInferenceMessage'>,)\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  inf-identity \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a123779-9f23-45b7-959a-98efed095dd6",
   "metadata": {},
   "source": [
    "It looks like we got a error, namely:\n",
    "```\n",
    "RuntimeError: The inference stage cannot handle input of <class 'morpheus.pipeline.messages.MultiMessage'>. Accepted input types: (<class 'morpheus.pipeline.messages.MultiInferenceMessage'>,)\n",
    "```\n",
    "In summary, it looks like the `inf-identity` stage is expecting a different kind of input than it was given by the `deserialize` stage just prior to it in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ebbe6-46df-412f-860b-014e549e3ef5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aec23a-2852-42fa-8fe2-30794d1c604b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b595334-ca86-4c44-a574-d9626f8117e8",
   "metadata": {},
   "source": [
    "For all inference stages in Morpheus pipelines, we need to preprocess our data in order to prepare it for the inference stage. Each of the 3 pipelines will perform different modification to the data in preprocessing but what they all share in common is the modification of the incoming data to be in the correct format to perform inference - just what we need to address our error above.\n",
    "\n",
    "Taking that into consideration, let's add a `preprocess` stage prior to the `inf-identity` stage. Please note, `inf-identity` currently prints tuples displaying inference output dimensions. This unintended behavior is being removed in upcoming Morpheus releases, and you can presently disregard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a849f4f0-be0b-4339-a206-5c1855fd6407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n",
      "(256, 29)\n",
      "(256, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(256, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(256, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(218, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(8, 29)\n",
      "(2, 29)\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-identity \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88da1d-4376-4634-8133-28b1678c8a98",
   "metadata": {},
   "source": [
    "Now it would appear our pipeline has run without error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a60f0b-9776-4253-ae9e-3df2638d7d1a",
   "metadata": {},
   "source": [
    "### Compare Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490566e0-e6fa-4d39-b33a-3cbc08dde78a",
   "metadata": {},
   "source": [
    "As we did in the previous section, let's compare the input and output data to see what impact the pipeline has had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67ef605-c7f8-4777-888c-818a15e8185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d0e1a1-57f1-470e-896b-56ae1f302eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_json('nvsmi.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574dff90-4504-42fb-9392-74656ae9d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_json('output.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10be0d66-5224-4bf6-9658-eab017de8cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 175)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d063fb34-3d13-49ef-badf-0312f9399fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 175)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f214828-91fc-41b9-a6cd-879862ac79dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nvidia_smi_log.timestamp                               object\n",
       "nvidia_smi_log.gpu.pci.tx_util                         object\n",
       "nvidia_smi_log.gpu.pci.rx_util                         object\n",
       "nvidia_smi_log.gpu.fb_memory_usage.used                object\n",
       "nvidia_smi_log.gpu.fb_memory_usage.free                object\n",
       "                                                    ...      \n",
       "nvidia_smi_log.gpu.utilization.decoder_util            object\n",
       "nvidia_smi_log.gpu.utilization.encoder_util            object\n",
       "nvidia_smi_log.gpu.uuid                                object\n",
       "nvidia_smi_log.gpu.vbios_version                       object\n",
       "timestamp                                      datetime64[ns]\n",
       "Length: 175, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb3e07d-84fb-4164-939d-abfb00c656c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nvidia_smi_log.timestamp                               object\n",
       "nvidia_smi_log.gpu.pci.tx_util                          int64\n",
       "nvidia_smi_log.gpu.pci.rx_util                          int64\n",
       "nvidia_smi_log.gpu.fb_memory_usage.used                 int64\n",
       "nvidia_smi_log.gpu.fb_memory_usage.free                 int64\n",
       "                                                    ...      \n",
       "nvidia_smi_log.gpu.utilization.decoder_util            object\n",
       "nvidia_smi_log.gpu.utilization.encoder_util            object\n",
       "nvidia_smi_log.gpu.uuid                                object\n",
       "nvidia_smi_log.gpu.vbios_version                       object\n",
       "timestamp                                      datetime64[ns]\n",
       "Length: 175, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01240a40-e136-4d08-88ff-476b796f0887",
   "metadata": {},
   "source": [
    "Here we can see already that there are significant differences between the source and output data dtypes. In particular it would appear that in service of preparing the data for inference, many columns have had their data type changed to a numerical form. This makes sense given the expectations of ML/DL models, and it serves as a great convenience that Morpheus takes care of this preprocessing for us. Here is a more specific example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31365831-6f37-4f17-9b3e-5984e170a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3909 MiB'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source['nvidia_smi_log.gpu.fb_memory_usage.used'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6010d2-a44d-486d-ba7c-41abbf5d9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['nvidia_smi_log.gpu.fb_memory_usage.used'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62416abb-f80c-4673-9498-6ef8df436fcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85704114-fded-4804-989a-e3bbe38b18e9",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225369c-0e2d-4d75-9b3d-1d11f7e46227",
   "metadata": {},
   "source": [
    "Now that you can add no-op inference, and the prerequisite preprocessing to a Morpheus pipeline, let's turn our attention to performing more-relevant work.\n",
    "\n",
    "Next we will give a brief introduction to the Triton inference server, which is available in Morpheus as an inference backend, after which we will turn our attention to performing meaningful inference using Triton in a Morpheus pipeline.\n",
    "\n",
    "Please continue to the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
