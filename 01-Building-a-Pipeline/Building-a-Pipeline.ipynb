{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d0782c-9e75-4fcf-bbc8-be45a1ba75a5",
   "metadata": {},
   "source": [
    "![DLI Header](../images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb0f43-4901-46d8-97b7-1b90fe721ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building Morpheus Pipelines with the Morpheus CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1cd5bb-982e-4cc1-94f3-f4725c481bad",
   "metadata": {},
   "source": [
    "In this notebook you are going to learn how to build a very basic Morpheus pipeline using the `morpheus` command-line interface (CLI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830a85d-d5c3-4bd8-b00f-95b26ae5faaf",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd2dc0-d0a6-4d84-a317-e0d56db054ce",
   "metadata": {},
   "source": [
    "By the end of this notebook you will:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead89244-719a-4e6b-9308-468e2f028cdf",
   "metadata": {},
   "source": [
    "- Know the 3 different kinds of Morpheus pipelines and their high-level differences.\n",
    "- Know the most basic constraints for building a pipeline.\n",
    "- Know how to use the `--help` option to get more information from Morpheus.\n",
    "- Be able to build an \"identity\" pipeline.\n",
    "- Be able to customize pipeline output fields.\n",
    "- Be able to use `--DEBUG` output to better understand pipeline stage inputs and outputs.\n",
    "- Be able to add performance monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebc566-022d-47b8-8882-ed30cffee1cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234925f-741e-4bde-a5ab-a16e6e1c6733",
   "metadata": {},
   "source": [
    "## Basic Pipeline Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52419b7d-c97b-4f21-9769-4bb0f4041263",
   "metadata": {},
   "source": [
    "When using the Morpheus CLI to construct pipelines, all pipelines follow this basic structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31619487-aeaf-4203-824a-6e2b803157b0",
   "metadata": {},
   "source": [
    "- Call `morpheus run`.\n",
    "- Specify the type of pipeline to run: either `pipeline-fil`, `pipeline-ae`, or `pipeline-nlp`.\n",
    "- Specify a source object for the pipeline, typically either a [Kafka](https://kafka.apache.org/) topic, or files from disk.\n",
    "- Create a sequential list of stages along with their options. The output for one stage becomes the input for the next.\n",
    "- Specify the pipeline's output, typically either a Kafka topic, or files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f09937-d749-4a18-a81b-f1940d8f06f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9800869a-c6ef-4d9a-b117-b2fba0a793da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calling `morpheus run` in a Jupyter Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca3e00-c0de-43fb-b573-5f73aef6d91e",
   "metadata": {},
   "source": [
    "If you are unfamiliar with the Jupyter environment, you need to know that a notebook (like the one you are viewing) consists of two kinds of cells. The first kind of cell, where this text is written, consists of [Markdown](https://daringfireball.net/projects/markdown/) and allows us to display text and images.\n",
    "\n",
    "The second kind of cell is an executable code cell. Code cells always have brackets (`[ ]`) on their left. While the code cell is being executed an asterisk will appear inside the brackets `[*]` and after the cell is complete running, a number will appear inside the brackets to indicate its count in the number of executions that have taken place within the environment, for example `[1]`.\n",
    "\n",
    "There are several ways to execute a code cell. Perhaps the easiest is to either press `SHIFT + RETURN` which will execute the cell and move your cursor to the next cell, or, `CTRL + RETURN` which will execute the cell and leave your focus on it. You can also use your mouse to click the ▶️ icon in the menu near the top of the notebook pane.\n",
    "\n",
    "Please note that Jupyter code cells execute Python code by default. We can, however, prepend an exclamation point `!` to the cell to instead issue a command line command. Execute the following cell, which will issue the `morpheus run` command from a command line, resulting in the printing of the help message for `morpheus run`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4eae221-8693-48dd-9396-7186b86b3a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: morpheus run [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "Options:\n",
      "  --num_threads INTEGER RANGE     Number of internal pipeline threads to use\n",
      "                                  [default: 4; x>=1]\n",
      "  --pipeline_batch_size INTEGER RANGE\n",
      "                                  Internal batch size for the pipeline. Can be\n",
      "                                  much larger than the model batch size. Also\n",
      "                                  used for Kafka consumers  [default: 256;\n",
      "                                  x>=1]\n",
      "  --model_max_batch_size INTEGER RANGE\n",
      "                                  Max batch size to use for the model\n",
      "                                  [default: 8; x>=1]\n",
      "  --edge_buffer_size INTEGER RANGE\n",
      "                                  The size of buffered channels to use between\n",
      "                                  nodes in a pipeline. Larger values reduce\n",
      "                                  backpressure at the cost of memory. Smaller\n",
      "                                  values will push messages through the\n",
      "                                  pipeline quicker. Must be greater than 1 and\n",
      "                                  a power of 2 (i.e. 2, 4, 8, 16, etc.)\n",
      "                                  [default: 128; x>=2]\n",
      "  --use_cpp BOOLEAN               Whether or not to use C++ node and message\n",
      "                                  types or to prefer python. Only use as a\n",
      "                                  last resort if bugs are encountered\n",
      "                                  [default: True]\n",
      "  --help                          Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  pipeline-ae   Run the inference pipeline with an AutoEncoder model\n",
      "  pipeline-fil  Run the inference pipeline with a FIL model\n",
      "  pipeline-nlp  Run the inference pipeline with a NLP model\n"
     ]
    }
   ],
   "source": [
    "!morpheus run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76053b03-cbd9-42ca-98f8-eeea1c64a7fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calling `morpheus run` in a Jupyter Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db6c16-196a-42f6-842c-a13cabc46a26",
   "metadata": {},
   "source": [
    "For use cases where the output is minimal, using a code cell prefixed with `!` to issue command line commands makes a lot of sense. Many times however, we would like to issue command line commands that are long running, have a lot of output, or require interactivity. In these cases it makes more sense to use an actual terminal to issue commands.\n",
    "\n",
    "There are several ways to open a terminal in Jupyter. For now, use Jupyter's _File_ menu, click _New Launcher_ and from the launcher screen that appears, click the _Terminal_ button. Doing so will open a new tab in the Jupyter environment running a terminal with access to the same file system that this notebook is running in. You can navigate between terminals and notebooks at any time.\n",
    "\n",
    "Open a Jupyter terminal now, and from the command line prompt that appears, issue the `morpheus run` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b2b24-1fe1-4173-83f2-18387648ec60",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c3c6a-8884-440d-b933-df2891fdf73a",
   "metadata": {},
   "source": [
    "## Three Kinds of Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3a92c-452d-4ec4-893e-215173c8ed73",
   "metadata": {},
   "source": [
    "At present, Morpheus ships with the ability to run three different kinds of pipelines. Each pipeline is centered around the kind of inference that it can perform on data in the pipeline, and provides additional configurations to that end.\n",
    "\n",
    "We will be looking at each of these pipeline types in detail during the workshop, but for now, here is a very high level summary of them each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc379a1-40c3-4003-aa43-c7e413aa119b",
   "metadata": {},
   "source": [
    "### Forest Inference Library (FIL) Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ad441-bdf8-4457-a401-86c4cfe49bb2",
   "metadata": {},
   "source": [
    "`pipeline-fil` can perform inference on data using the [RAPIDS Forest Inference Library](https://medium.com/rapids-ai/rapids-forest-inference-library-prediction-at-100-million-rows-per-second-19558890bc35), or FIL. FIL provides accelerated inference for tree-based models, including gradient-boosted decision tree models (like those from XGBoost and LightGBM) and random forests. Using `pipeline-fil` we can construct pipelines that perform lightning-fast classification inference using tree-based machine learning models we provide.\n",
    "\n",
    "In this workshop you will use `pipeline-fil` to classify whether or not users are using system compute resources in malicious ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79493b9f-b4ec-4fd7-94a4-ccdf442367be",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP) Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83519a4d-138c-43c6-b120-6451108729ba",
   "metadata": {},
   "source": [
    "`pipeline-nlp` can perform inference on data using Natural Language Processing (NLP) models such as those based on the [BERT](https://huggingface.co/docs/transformers/model_doc/bert) architecture.\n",
    "\n",
    "NLP can be a powerful tool in the cybersecurity toolkit, as many cybersecurity problems can be viewed as natural language processing problems. The ubiquitous use of regex for log parsing in cybersecurity workflows is a sign that analysts need linguistic information about the data they oversee. NLP models can generalize their understanding of data and therefore identify data in need of action, even when the specific characters of the data have yet to be seen by analysts.\n",
    "\n",
    "In this workshop you will use `pipeline-nlp` to detect the presence of sensitive information in PCAP logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84c377-baa5-4001-b7b2-8b7900706df3",
   "metadata": {},
   "source": [
    "### Auto-Encoder (AE) Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a3a46-dd72-4a55-aa84-1fb23c0dfb4f",
   "metadata": {},
   "source": [
    "`pipeline-ae` can perform two kinds of unsupervised inference on data: anomaly detection through the use of [autoencoders](https://en.wikipedia.org/wiki/Autoencoder), and time series anomaly detection through the use of [Fast Fourier Transforms](https://en.wikipedia.org/wiki/Fast_Fourier_transform) (FFT).\n",
    "\n",
    "In this workshop you will use `pipeline-ae` to create \"digital fingerprints\" of system users and services and to identify when users or services are behaving unlike their digital fingerprint and potentially therefore compromised and acting under the agency of attackers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec1720-6e63-4b2b-a1f4-7d6827ffacbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc8b06-5cfa-4e4b-a0db-0c40451a05b7",
   "metadata": {},
   "source": [
    "## Using `--help` to Explore Pipeline Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78ef7a-8617-436d-8f60-89f68e657429",
   "metadata": {},
   "source": [
    "As you begin to learn how to build Morpheus pipelines with the CLI, you will often want information about the available options to you. A great way to quickly get this information is to use the `--help` flag after a CLI command or subcommand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9001b3-6d17-4b59-9d30-ffb4fc1263b9",
   "metadata": {},
   "source": [
    "We are going to use this method to help us construct our first very simple Morpheus pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee17e22-8096-4c7b-9992-a6276f678c34",
   "metadata": {},
   "source": [
    "### Basic Pipeline Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f41e5-9446-4be7-a475-ed0fe569055a",
   "metadata": {},
   "source": [
    "As an exercise in preparation for our first pipeline, execute the following command to see the help text for `pipeline-fil`. Spend a few minutes reading the output and be prepared to discuss the following questions:\n",
    "\n",
    "- What are the 4 rules all FIL pipelines must follow?\n",
    "- What kind of data sources are currently supported?\n",
    "- What does the `deserialize` stage do? Where in a pipeline must it be used?\n",
    "- Does the FIL pipeline have to perform inference on the data passing through it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4d79d2-c88f-4f89-a1cd-5f8b0b475bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: morpheus run pipeline-fil [OPTIONS] COMMAND1 [ARGS]... [COMMAND2\n",
      "                                 [ARGS]...]...\n",
      "\n",
      "  Configure and run the pipeline. To configure the pipeline, list the stages\n",
      "  in the order that data should flow. The output of each stage will become the\n",
      "  input for the next stage. For example, to read, classify and write to a\n",
      "  file, the following stages could be used\n",
      "\n",
      "  pipeline from-file --filename=my_dataset.json deserialize preprocess inf-triton --model_name=my_model\n",
      "  --server_url=localhost:8001 filter --threshold=0.5 to-file --filename=classifications.json\n",
      "\n",
      "  Pipelines must follow a few rules:\n",
      "  1. Data must originate in a source stage. Current options are `from-file` or `from-kafka`\n",
      "  2. A `deserialize` stage must be placed between the source stages and the rest of the pipeline\n",
      "  3. Only one inference stage can be used. Zero is also fine\n",
      "  4. The following stages must come after an inference stage: `add-class`, `filter`, `gen-viz`\n",
      "\n",
      "Options:\n",
      "  --model_fea_length INTEGER RANGE\n",
      "                                  Number of features trained in the model\n",
      "                                  [default: 29; x>=1]\n",
      "  --labels_file FILE              Specifies a file to read labels from in\n",
      "                                  order to convert class IDs into labels. A\n",
      "                                  label file is a simple text file where each\n",
      "                                  line corresponds to a label. If unspecified,\n",
      "                                  only a single output label is created for\n",
      "                                  FIL\n",
      "  --columns_file FILE             Specifies a file to read column features.\n",
      "                                  [default: data/columns_fil.txt]\n",
      "  --viz_file FILE                 Save a visualization of the pipeline at the\n",
      "                                  specified location\n",
      "  --help                          Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  add-class     Add detected classifications to each message\n",
      "  add-scores    Add probability scores to each message\n",
      "  buffer        (Deprecated) Buffer results\n",
      "  delay         (Deprecated) Delay results for a certain duration\n",
      "  deserialize   Deserialize source data from JSON.\n",
      "  dropna        Drop null data entries from a DataFrame\n",
      "  filter        Filter message by a classification threshold\n",
      "  from-file     Load messages from a file\n",
      "  from-kafka    Load messages from a Kafka cluster\n",
      "  inf-identity  Perform a no-op inference for testing\n",
      "  inf-pytorch   Perform inference with PyTorch\n",
      "  inf-triton    Perform inference with Triton\n",
      "  mlflow-drift  Report model drift statistics to ML Flow\n",
      "  monitor       Display throughput numbers at a specific point in the pipeline\n",
      "  preprocess    Convert messages to tokens\n",
      "  serialize     Include & exclude columns from messages\n",
      "  to-file       Write all messages to a file\n",
      "  to-kafka      Write all messages to a Kafka cluster\n",
      "  validate      Validates pipeline output against an expected output\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c315655-6cef-4f93-9c55-49dac934ac90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc64dfc-6a97-421b-8fa8-92e140dea4f6",
   "metadata": {},
   "source": [
    "## Identity Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e13f47-aab4-46e7-9cbf-a567bb668f69",
   "metadata": {},
   "source": [
    "Let's try to create the most basic pipeline possible, an identity pipeline that simply reads data from a file and writes it back without changes to another file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79f3d3-f86d-4782-99f2-f9301f0acb9e",
   "metadata": {},
   "source": [
    "### Data Source Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096cfdcc-a767-4088-be11-2517e6e8b08f",
   "metadata": {},
   "source": [
    "The help text above provides us with some helpful information to get started. First:\n",
    "```\n",
    "1. Data must originate in a source stage. Current options are `from-file` or `from-kafka`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c6dfd-a197-436e-a333-05a14e76b6c7",
   "metadata": {},
   "source": [
    "If we look at the help text for the `from-file` stage we see that we can provide it a `--filename` flag with an input filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc04afa6-f424-453a-a6f8-6ace5c61294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "Usage: morpheus run pipeline-fil from-file [OPTIONS]\n",
      "\n",
      "Options:\n",
      "  --filename FILE              Input filename\n",
      "  --iterative                  Iterative mode will emit dataframes one at a\n",
      "                               time. Otherwise a list of dataframes is\n",
      "                               emitted. Iterative mode is good for\n",
      "                               interleaving source stages.\n",
      "  --file-type [auto|csv|json]  Indicates what type of file to read. Specifying\n",
      "                               'auto' will determine the file type from the\n",
      "                               extension.  [default: auto]\n",
      "  --repeat INTEGER RANGE       Repeats the input dataset multiple times.\n",
      "                               Useful to extend small datasets for debugging.\n",
      "                               [default: 1; x>=1]\n",
      "  --filter_null BOOLEAN        Whether or not to filter rows with null 'data'\n",
      "                               column. Null values in the 'data' column can\n",
      "                               cause issues down the line with processing.\n",
      "                               Setting this to True is recommended.  [default:\n",
      "                               True]\n",
      "  --help                       Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil from-file --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc4727-5b47-4e59-a708-8dc269679777",
   "metadata": {},
   "source": [
    "For this exercise we have provided the file `nvsmi.jsonlines`. We will be looking in more detail at this data later in the workshop, but for now just now that it is available to us in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d15d4b-21a7-4436-93b6-f68b87b1de5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building-a-Pipeline.ipynb  data  images  nvsmi.jsonlines\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41011a-d6bf-4537-b375-5fe47e6dbcf9",
   "metadata": {},
   "source": [
    "Therefore we might begin forming our pipeline as such:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf0b63-03e2-40b7-afdb-c0909c74eb6d",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce536e2-a3df-4916-8569-556c763b18fc",
   "metadata": {},
   "source": [
    "### Deserialize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39a09a-9066-4bb2-9810-43790dd15d90",
   "metadata": {},
   "source": [
    "The help message above also indicated:\n",
    "```\n",
    "2. A `deserialize` stage must be placed between the source stages and the rest of the pipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1acf655-7f7f-4f8b-89be-be09bb80f0f6",
   "metadata": {},
   "source": [
    "Therefore we might extend our pipeline as such:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f446723-3b53-4bb8-83ab-6576509beb5d",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines\n",
    "  deserialize\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df14d4d-bd76-4bc5-94dd-806bcc1e97ef",
   "metadata": {},
   "source": [
    "### Write to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb369da3-095a-45de-b8e3-8114fcc4edd8",
   "metadata": {},
   "source": [
    "Since our goal is simply to write the data back to file unchanged we can use the `to-file` stage which also takes a `--filename` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd812e73-938f-49af-8c5d-568a1f6368aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "Usage: morpheus run pipeline-fil to-file [OPTIONS]\n",
      "\n",
      "Options:\n",
      "  --filename PATH  The file to write to  [required]\n",
      "  --overwrite      Whether or not to overwrite the target file\n",
      "  --help           Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil to-file --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef5392-7798-492b-b3d2-5146be4d65f1",
   "metadata": {},
   "source": [
    "Therefore we will extend our pipeline as such:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a8e3c-9672-4d22-bef2-244ca24be262",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines\n",
    "  deserialize\n",
    "  to-file --filename output.jsonlines\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a77ba-c860-406e-82fe-73d1b6bc558e",
   "metadata": {},
   "source": [
    "### Execute the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810093ed-5dfd-41ea-8427-ad259dbaa49c",
   "metadata": {},
   "source": [
    "Let's execute the pipeline as we've constructed it and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f866d18e-fddd-4028-b89c-05627a3e03e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/morpheus/bin/morpheus\", line 11, in <module>\n",
      "    sys.exit(run_cli())\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/cli.py\", line 1395, in run_cli\n",
      "    cli(obj={}, auto_envvar_prefix='MORPHEUS', show_default=True, prog_name=\"morpheus\")\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1689, in invoke\n",
      "    return _process_result(rv)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 1626, in _process_result\n",
      "    value = ctx.invoke(self._result_callback, value, **ctx.params)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/click/decorators.py\", line 26, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/cli.py\", line 557, in post_pipeline\n",
      "    pipeline.run()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 1239, in run\n",
      "    asyncio.run(self._do_run())\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/asyncio/base_events.py\", line 616, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 1214, in _do_run\n",
      "    self.build_and_start()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 1038, in build_and_start\n",
      "    self.start()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 998, in start\n",
      "    self._neo_executor.start()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 960, in inner_build\n",
      "    s.build(seg)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 526, in build\n",
      "    dep.build(seg, do_propagate=do_propagate)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 526, in build\n",
      "    dep.build(seg, do_propagate=do_propagate)\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 502, in build\n",
      "    in_ports_pairs = self._pre_build()\n",
      "  File \"/opt/conda/envs/morpheus/lib/python3.8/site-packages/morpheus/pipeline/pipeline.py\", line 765, in _pre_build\n",
      "    raise RuntimeError(\"The {} stage cannot handle input of {}. Accepted input types: {}\".format(\n",
      "RuntimeError: The to-file stage cannot handle input of <class 'morpheus.pipeline.messages.MultiMessage'>. Accepted input types: (<class 'morpheus.pipeline.messages.MessageMeta'>,)\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  to-file --filename output.jsonlines --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a18545-a534-4cec-bc96-44db53137335",
   "metadata": {},
   "source": [
    "It looks like we got an error:\n",
    "```\n",
    "RuntimeError: The to-file stage cannot handle input of <class 'morpheus.pipeline.messages.MultiMessage'>. Accepted input types: (<class 'morpheus.pipeline.messages.MessageMeta'>,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b32d3-2b5d-4800-8b1b-3b49a9217c05",
   "metadata": {},
   "source": [
    "In summary this error states that the data entering the `to-file` stage is not of the correct type. Recall that in Morpheus pipelines, the output of one stage is the input to the next, so it would seem that the output of the `deserialize` stage is not of the type that the `to-file` stage expects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033000e2-2377-4541-bb85-25f473b98b00",
   "metadata": {},
   "source": [
    "### Serialize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcdc31-25f9-4636-aa0e-38b1c3b2c0d7",
   "metadata": {},
   "source": [
    "What we need to fix this particular error is to add a `serialize` stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833219fb-46de-4d17-a0e7-fd7af582240f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  serialize     Include & exclude columns from messages\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil --help | grep ' serialize'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219cd1d-3afb-404f-97ce-60ffda8ec68f",
   "metadata": {},
   "source": [
    "This makes our simple identity pipeline the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5722c4-bd14-4f0b-a0c0-1eba1efcb039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  serialize \\\n",
    "  to-file --filename output.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895cd4c-8011-4322-a9cc-fce9037c646b",
   "metadata": {},
   "source": [
    "We can now see that a new `output.jsonlines` file has been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d586ca11-83d3-4430-909f-ff7e7086e7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building-a-Pipeline.ipynb  data  images  nvsmi.jsonlines  output.jsonlines\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353d3ef-277a-4943-99a8-5f66a799c959",
   "metadata": {},
   "source": [
    "### Compare Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8de26-0c8a-45e1-884b-ceb0a28e382b",
   "metadata": {},
   "source": [
    "Let's compare the input and output data since our intention was to write to file the same data we read. We will start by reading the JSON lines files into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67ef605-c7f8-4777-888c-818a15e8185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d0e1a1-57f1-470e-896b-56ae1f302eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_json('nvsmi.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574dff90-4504-42fb-9392-74656ae9d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_json('output.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fedc313-1194-495d-8cc8-a284f39bd800",
   "metadata": {},
   "source": [
    "Next we compare their shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10be0d66-5224-4bf6-9658-eab017de8cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 175)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d063fb34-3d13-49ef-badf-0312f9399fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 175)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7016eaf9-8e23-434d-a53e-a2bbb344d9ea",
   "metadata": {},
   "source": [
    "Next let's compare the dataframes directly. `df.compare(df2)` will return any differences between 2 dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f214828-91fc-41b9-a6cd-879862ac79dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-12 09:46:00.956650240</td>\n",
       "      <td>2021-03-12 09:46:00.956650496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-12 09:48:32.237897984</td>\n",
       "      <td>2021-03-12 09:48:32.237897472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-03-12 09:49:34.100829952</td>\n",
       "      <td>2021-03-12 09:49:34.100829696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-03-12 09:50:35.820171776</td>\n",
       "      <td>2021-03-12 09:50:35.820171520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-03-12 09:51:06.891563008</td>\n",
       "      <td>2021-03-12 09:51:06.891562752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>2021-03-12 20:27:18.598337792</td>\n",
       "      <td>2021-03-12 20:27:18.598337536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>2021-03-12 20:27:49.341308928</td>\n",
       "      <td>2021-03-12 20:27:49.341308672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2021-03-12 20:29:20.879171840</td>\n",
       "      <td>2021-03-12 20:29:20.879171584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2021-03-12 20:33:26.666036736</td>\n",
       "      <td>2021-03-12 20:33:26.666036480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2021-03-12 20:34:28.820807936</td>\n",
       "      <td>2021-03-12 20:34:28.820807680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp                              \n",
       "                              self                         other\n",
       "0    2021-03-12 09:46:00.956650240 2021-03-12 09:46:00.956650496\n",
       "5    2021-03-12 09:48:32.237897984 2021-03-12 09:48:32.237897472\n",
       "7    2021-03-12 09:49:34.100829952 2021-03-12 09:49:34.100829696\n",
       "9    2021-03-12 09:50:35.820171776 2021-03-12 09:50:35.820171520\n",
       "10   2021-03-12 09:51:06.891563008 2021-03-12 09:51:06.891562752\n",
       "...                            ...                           ...\n",
       "1227 2021-03-12 20:27:18.598337792 2021-03-12 20:27:18.598337536\n",
       "1228 2021-03-12 20:27:49.341308928 2021-03-12 20:27:49.341308672\n",
       "1231 2021-03-12 20:29:20.879171840 2021-03-12 20:29:20.879171584\n",
       "1239 2021-03-12 20:33:26.666036736 2021-03-12 20:33:26.666036480\n",
       "1241 2021-03-12 20:34:28.820807936 2021-03-12 20:34:28.820807680\n",
       "\n",
       "[441 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.compare(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5815b-9170-4d08-8e57-6f7692a424a8",
   "metadata": {},
   "source": [
    "It would appear that the timestamp fields have changed slightly during the process of serialization and deserialization. Let's round these time values to the nearest millisecond and then compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "690f43fa-3910-4b64-a50c-321ea1ba8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "source['timestamp'] = source['timestamp'].dt.round('ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4889b133-9faa-4873-9258-998237ac4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['timestamp'] = output['timestamp'].dt.round('ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4aa53eb-06f4-40d6-b250-9b073eec32df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.compare(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b21c3-a2e0-4058-b751-7e20d5552a1f",
   "metadata": {},
   "source": [
    "No output indicates the dataframes are identical, and we can reasonably state that we have achieved creating a very basic identity pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b3040-a6b2-4f16-a0e6-ac747e9ac338",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e82bc2-bf1b-478a-9bfd-b91cdd5ab93f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Customizing Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a5005-c7b8-4d9e-a035-6420da20af6a",
   "metadata": {},
   "source": [
    "We may only be interested in certain parts of our data, and wish only to write some of it to our source. The `serialize` stage provides options to customize what will be passed onto later stages of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82c54ecc-215f-4722-a4de-4ff1176f45ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "Usage: morpheus run pipeline-fil serialize [OPTIONS]\n",
      "\n",
      "Options:\n",
      "  --include TEXT  Which columns to include from MultiMessage into JSON. Can be\n",
      "                  specified multiple times. Resulting columns is the\n",
      "                  intersection of all regex. Include applied before exclude\n",
      "                  [default: (All Columns)]\n",
      "  --exclude TEXT  Which columns to exclude from MultiMessage into JSON. Can be\n",
      "                  specified multiple times. Resulting ignored columns is the\n",
      "                  intersection of all regex. Include applied before exclude\n",
      "                  [default: ^ID$, ^_ts_; required]\n",
      "  --help          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil serialize --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e696610-c963-4157-bd54-fd7ce58996e6",
   "metadata": {},
   "source": [
    "Here we run our simple pipeline again, but choose only to write 2 data fields to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39e80a06-5ecc-44fa-91f6-7c84ed955895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  serialize --include 'nvidia_smi_log.gpu.processes.process_info.1.process_name' --include 'nvidia_smi_log.gpu.product_name' \\\n",
    "  to-file --filename small_output.jsonlines --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0321fe2d-7030-4500-bfd1-1fadcd47ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"nvidia_smi_log.gpu.processes.process_info.1.process_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"tritonserver\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"nvidia_smi_log.gpu.product_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Tesla V100-SXM2-16GB\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Show the first entry in the output data, which only contains the 2 data fields we specified above.\n",
    "!cat small_output.jsonlines | jq -s '.[0]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9555e5-e7a6-4864-933a-27a04dd4eb1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892d873-44c5-49f8-beeb-73f59f201f9e",
   "metadata": {},
   "source": [
    "## Log Level Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214a2ca-46b5-4c12-a68b-060f42e1a311",
   "metadata": {},
   "source": [
    "Often when constructing pipelines it can be helpful to get more information about what the pipeline is doing. We can accomplish this by setting the Morpheus `--log_level` to `DEBUG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5f79f2f-e4f8-4ec2-877f-6aa78d4aabb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --log_level [CRITICAL|FATAL|ERROR|WARN|WARNING|INFO|DEBUG]\n"
     ]
    }
   ],
   "source": [
    "!morpheus --help | grep 'log_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd053dd-8183-4bf5-ae50-1e362fce06ca",
   "metadata": {},
   "source": [
    "We will do just that for our simple identity pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b211521-efbb-4489-938b-6cead0970f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[2mLoaded columns. Current columns: [['nvidia_smi_log.gpu.pci.tx_util', 'nvidia_smi_log.gpu.pci.rx_util', 'nvidia_smi_log.gpu.fb_memory_usage.used', 'nvidia_smi_log.gpu.fb_memory_usage.free', 'nvidia_smi_log.gpu.bar1_memory_usage.total', 'nvidia_smi_log.gpu.bar1_memory_usage.used', 'nvidia_smi_log.gpu.bar1_memory_usage.free', 'nvidia_smi_log.gpu.utilization.gpu_util', 'nvidia_smi_log.gpu.utilization.memory_util', 'nvidia_smi_log.gpu.temperature.gpu_temp', 'nvidia_smi_log.gpu.temperature.gpu_temp_max_threshold', 'nvidia_smi_log.gpu.temperature.gpu_temp_slow_threshold', 'nvidia_smi_log.gpu.temperature.gpu_temp_max_gpu_threshold', 'nvidia_smi_log.gpu.temperature.memory_temp', 'nvidia_smi_log.gpu.temperature.gpu_temp_max_mem_threshold', 'nvidia_smi_log.gpu.power_readings.power_draw', 'nvidia_smi_log.gpu.clocks.graphics_clock', 'nvidia_smi_log.gpu.clocks.sm_clock', 'nvidia_smi_log.gpu.clocks.mem_clock', 'nvidia_smi_log.gpu.clocks.video_clock', 'nvidia_smi_log.gpu.applications_clocks.graphics_clock', 'nvidia_smi_log.gpu.applications_clocks.mem_clock', 'nvidia_smi_log.gpu.default_applications_clocks.graphics_clock', 'nvidia_smi_log.gpu.default_applications_clocks.mem_clock', 'nvidia_smi_log.gpu.max_clocks.graphics_clock', 'nvidia_smi_log.gpu.max_clocks.sm_clock', 'nvidia_smi_log.gpu.max_clocks.mem_clock', 'nvidia_smi_log.gpu.max_clocks.video_clock', 'nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock']]\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n",
      "Config: \n",
      "{\n",
      "  \"ae\": null,\n",
      "  \"class_labels\": [\n",
      "    \"mining\"\n",
      "  ],\n",
      "  \"debug\": false,\n",
      "  \"edge_buffer_size\": 128,\n",
      "  \"feature_length\": 29,\n",
      "  \"fil\": {\n",
      "    \"feature_columns\": [\n",
      "      \"nvidia_smi_log.gpu.pci.tx_util\",\n",
      "      \"nvidia_smi_log.gpu.pci.rx_util\",\n",
      "      \"nvidia_smi_log.gpu.fb_memory_usage.used\",\n",
      "      \"nvidia_smi_log.gpu.fb_memory_usage.free\",\n",
      "      \"nvidia_smi_log.gpu.bar1_memory_usage.total\",\n",
      "      \"nvidia_smi_log.gpu.bar1_memory_usage.used\",\n",
      "      \"nvidia_smi_log.gpu.bar1_memory_usage.free\",\n",
      "      \"nvidia_smi_log.gpu.utilization.gpu_util\",\n",
      "      \"nvidia_smi_log.gpu.utilization.memory_util\",\n",
      "      \"nvidia_smi_log.gpu.temperature.gpu_temp\",\n",
      "      \"nvidia_smi_log.gpu.temperature.gpu_temp_max_threshold\",\n",
      "      \"nvidia_smi_log.gpu.temperature.gpu_temp_slow_threshold\",\n",
      "      \"nvidia_smi_log.gpu.temperature.gpu_temp_max_gpu_threshold\",\n",
      "      \"nvidia_smi_log.gpu.temperature.memory_temp\",\n",
      "      \"nvidia_smi_log.gpu.temperature.gpu_temp_max_mem_threshold\",\n",
      "      \"nvidia_smi_log.gpu.power_readings.power_draw\",\n",
      "      \"nvidia_smi_log.gpu.clocks.graphics_clock\",\n",
      "      \"nvidia_smi_log.gpu.clocks.sm_clock\",\n",
      "      \"nvidia_smi_log.gpu.clocks.mem_clock\",\n",
      "      \"nvidia_smi_log.gpu.clocks.video_clock\",\n",
      "      \"nvidia_smi_log.gpu.applications_clocks.graphics_clock\",\n",
      "      \"nvidia_smi_log.gpu.applications_clocks.mem_clock\",\n",
      "      \"nvidia_smi_log.gpu.default_applications_clocks.graphics_clock\",\n",
      "      \"nvidia_smi_log.gpu.default_applications_clocks.mem_clock\",\n",
      "      \"nvidia_smi_log.gpu.max_clocks.graphics_clock\",\n",
      "      \"nvidia_smi_log.gpu.max_clocks.sm_clock\",\n",
      "      \"nvidia_smi_log.gpu.max_clocks.mem_clock\",\n",
      "      \"nvidia_smi_log.gpu.max_clocks.video_clock\",\n",
      "      \"nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock\"\n",
      "    ]\n",
      "  },\n",
      "  \"log_config_file\": null,\n",
      "  \"log_level\": 10,\n",
      "  \"mode\": \"FIL\",\n",
      "  \"model_max_batch_size\": 8,\n",
      "  \"num_threads\": 4,\n",
      "  \"pipeline_batch_size\": 256\n",
      "}\u001b[0m\n",
      "CPP Enabled: True\u001b[0m\n",
      "====Registering Pipeline====\u001b[0m\n",
      "====Registering Pipeline Complete!====\u001b[0m\n",
      "====Starting Pipeline====\u001b[0m\n",
      "====Building Pipeline====\u001b[0m\n",
      "Added source: <from-file-0; FileSourceStage(filename=nvsmi.jsonlines, iterative=False, file_type=FileTypes.Auto, repeat=1, filter_null=True, cudf_kwargs=None)>\n",
      "  └─> morpheus.MessageMeta\u001b[0m\n",
      "Added stage: <deserialize-1; DeserializeStage()>\n",
      "  └─ morpheus.MessageMeta -> morpheus.MultiMessage\u001b[0m\n",
      "Added stage: <serialize-2; SerializeStage(include=[], exclude=['^ID$', '^_ts_'], fixed_columns=True)>\n",
      "  └─ morpheus.MultiMessage -> morpheus.MessageMeta\u001b[0m\n",
      "Added stage: <to-file-3; WriteToFileStage(filename=output.jsonlines, overwrite=True, file_type=FileTypes.Auto)>\n",
      "  └─ morpheus.MessageMeta -> morpheus.MessageMeta\u001b[0m\n",
      "====Building Pipeline Complete!====\u001b[0m\n",
      "\u001b[2mStarting! Time: 1712294629.0516486\u001b[0m\n",
      "====Pipeline Started====\u001b[0m\n",
      "====Pipeline Complete====\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!morpheus --log_level=DEBUG run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  serialize \\\n",
    "  to-file --filename output.jsonlines --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96679848-add7-49e9-b628-49e07cc9e0e7",
   "metadata": {},
   "source": [
    "This output gives a lot of helpful information, including many of the default values we may not have explicitly set, for example:\n",
    "```sh\n",
    "Config: \n",
    "{\n",
    "  \"ae\": null,\n",
    "  \"class_labels\": [\n",
    "    \"mining\"\n",
    "  ],\n",
    "  \"debug\": false,\n",
    "  \"edge_buffer_size\": 128,\n",
    "  \"feature_length\": 29,\n",
    "  \"fil\": {\n",
    "    \"feature_columns\": []\n",
    "  },\n",
    "  \"log_config_file\": null,\n",
    "  \"log_level\": 10,\n",
    "  \"mode\": \"FIL\",\n",
    "  \"model_max_batch_size\": 8,\n",
    "  \"num_threads\": 4,\n",
    "  \"pipeline_batch_size\": 256\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803d50c-f515-490e-8c1d-7ab96084dc26",
   "metadata": {},
   "source": [
    "...the input and output types for each stage, for example:\n",
    "```sh\n",
    "└─ morpheus.MultiMessage -> morpheus.MessageMeta\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f17c1-7e4d-4468-8524-984365a70c4d",
   "metadata": {},
   "source": [
    "...and also the actual pipeline function calls from the Morpheus source code, in case you need or want to [go digging deeper](https://github.com/nv-morpheus/Morpheus/blob/64564e1eb051f6820b13772074736e09bdc8941f/morpheus/stages/preprocess/deserialize_stage.py#L33), for example:\n",
    "```sh\n",
    "DeserializeStage()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebbd8a6-22eb-4cde-8bfa-c78e0514fbed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0722008-095a-450d-8627-a34e0373f553",
   "metadata": {},
   "source": [
    "## Performance Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0000641d-eb6a-467b-a02d-8a972b1e876d",
   "metadata": {},
   "source": [
    "Especially when you begin to construct complicated pipelines to work on massive amounts data, you may very well wish to information about the performance of your pipeline. This can be done by adding `monitor` stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e32fea81-234e-43cd-9134-fb93cb65205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  monitor       Display throughput numbers at a specific point in the pipeline\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil --help | grep ' monitor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e4ad6db-4ae1-4571-aa95-14a1fea3b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "Usage: morpheus run pipeline-fil monitor [OPTIONS]\n",
      "\n",
      "Options:\n",
      "  --description TEXT  Header message to use for this monitor  [required]\n",
      "  --smoothing FLOAT   How much to average throughput numbers. 0=full average,\n",
      "                      1=instantaneous  [default: 0.05]\n",
      "  --unit TEXT         Units to use for data rate\n",
      "  --delayed_start     When delayed_start is enabled, the progress bar will not\n",
      "                      be shown until the first message is received. Otherwise,\n",
      "                      the progress bar is shown on pipeline startup and will\n",
      "                      begin timing immediately. In large pipelines, this\n",
      "                      option may be desired to give a more accurate timing.\n",
      "  --help              Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil monitor --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36093684-724d-4bc4-9984-03e5939ebdce",
   "metadata": {},
   "source": [
    "As shown above, `monitor` stages will report throughput numbers at a specific point in the pipeline. Here we rewrite our simple identity pipeline to print throughput information about the `deserialize` stage.\n",
    "\n",
    "Because the output of this command is going to update as throughput changes over the life of the pipeline, we would do better to run it in an actual terminal, and not a code cell where output is static. To do this, copy the following cell and paste it into an open Jupyter terminal (remember you can open one by doing _File -> New Launcher -> Terminal_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711ab81-7fff-4bc7-ae47-75cc4c134b6f",
   "metadata": {},
   "source": [
    "```sh\n",
    "cd /dli/task/01-Building-a-Pipeline\n",
    "\n",
    "morpheus --log_level=DEBUG run pipeline-fil \\\n",
    "  from-file --filename nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  monitor --description \"Deserialize Rate\" --unit msg \\\n",
    "  serialize \\\n",
    "  to-file --filename output.jsonlines --overwrite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ed430-fd3b-4ef2-b357-9cb3a74c26e8",
   "metadata": {},
   "source": [
    "You will have noticed the addition of throughput numbers to the output, for example:\n",
    "```\n",
    "Deserialize Rate[Complete]: 1242msg [00:00, 5057.80msg/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188517c1-5f11-49a3-9c8f-19546e6bcc3d",
   "metadata": {},
   "source": [
    "Given the simplicity of our current pipeline, this isn't yet of much use, but as your pipelines grow more sophisticated, you will likely wish to include `monitor` stages in a variety of locations in your pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143e468-2dca-4732-a972-f226cd322b82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24600d5a-2398-42eb-86d1-0445e472da2c",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4262fd2-dbd6-4195-89b5-7e55ae369840",
   "metadata": {},
   "source": [
    "In this notebook you learned how to construct very basic Morpheus pipelines, including how to use `--help` and `DEBUG` to get more information, and how to monitor throughput with the `monitor` stage. You learned at a very high level about the 3 different kind of pipelines Morpheus offered, and also how to work with the Morpheus CLI in this interactive Jupyter environment.\n",
    "\n",
    "One of the main goals of this workshop is for you to feel comfortable constructing Morpheus pipelines, and to that effect, in the next section, you are going to use what you have learned so far to construct your first Morpheus pipeline from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f033c9-1b76-4b97-bfab-e278be608c0f",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debdb999-d178-4f6e-9afc-d973457d8c4b",
   "metadata": {},
   "source": [
    "Each separate notebook in this JupyterLab environment runs its own Jupyter \"kernel\" which may utilize GPU memory and other system resources. In order to avoid unforeseen issues between separate notebooks sharing GPU resources, you should shut down each notebook's kernel before proceeding to the next notebook.\n",
    "\n",
    "This can be done by right-clicking the notebook name in the left-hand side file viewer and selecting \"Shut Down Kernel\" as shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764b48a-3bda-4f73-8d9b-942ace49abee",
   "metadata": {},
   "source": [
    "![shut down kernel](images/stop_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdfb830-01af-49ba-b454-e6f7404e10a2",
   "metadata": {},
   "source": [
    "After shutting down the kernel, please continue to the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
