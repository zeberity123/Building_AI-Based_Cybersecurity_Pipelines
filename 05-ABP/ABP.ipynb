{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194a3c15-6e50-4ff0-a39d-833ee85e39f9",
   "metadata": {},
   "source": [
    "## ![DLI Header](../images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb0f43-4901-46d8-97b7-1b90fe721ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Anomalous Behavior Profiling (ABP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ae4ea-6b92-43da-b094-177b570ebb9d",
   "metadata": {},
   "source": [
    "In this notebook you are going to utilize the FIL pipeline to perform anomalous behavior profiling on GPU metric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7604984-f023-49dc-8605-1244705e2247",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead89244-719a-4e6b-9308-468e2f028cdf",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "\n",
    "- Perform actual inference in a Morpheus pipeline.\n",
    "- Utilize a Triton backend from a Morpheus pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e7ca7-6f90-4859-92c6-2496a1587555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db31d5-a94e-4af8-9d97-49638175fb8d",
   "metadata": {},
   "source": [
    "## The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cc984-4bde-4012-93ce-36abb97c78ba",
   "metadata": {},
   "source": [
    "Morpheus was developed at NVIDIA and in this notebook you are going to be using Morpheus to address a real cybersecurity problem that NVIDIA has had to address: the abuse of GPU resources for cryptocurrency mining.\n",
    "\n",
    "You can imagine a massive cluster containing GPU resources that are intended for deep learning research and development. This cluster is expensive to run and maintain, and has very high demand for its use on legitimate projects. One problem is that some may see access to this GPU-enabled cluster as an opportunity to run cryptocurrency mining software for their own profit, which is obviously unethical, and blocks a scarce resource from being utilized for its intended purpose.\n",
    "\n",
    "Consider the difficulty of solving this problem using traditional label-based methods. Cryptocurrency mining programs and process can easily have their names and outputs modified to be undetectable, and furthermore, spikes in GPU utilization are also not sufficient to identify such use since the expected workloads for the cluster are often long-running and compute-intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab82e2-762d-4d4a-9254-d8737c70e03c",
   "metadata": {},
   "source": [
    "## A Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b713c78-73c7-4ed3-807d-389218e64e2f",
   "metadata": {},
   "source": [
    "Although the difference between acceptable deep learning workflows and cryptocurrency mining are very difficult to detect to the human eye, we can use AI. In this case, we can train an XGBoost model using GPU metric logs we create while running both acceptable and non-acceptable GPU workloads that we can label appropriately. The model will be capable to classify one class of workload vs. another using features that a human eye may not have been able to observe or understand on their own.\n",
    "\n",
    "Using Morpheus, we can now load this trained model into Triton, and then construct a pipeline that ingests GPU metrics in real time and performs inference on all incoming data, labeling any data that the model classifies as participating in cryptocurrency mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d01b89-1ea1-45ee-aa5a-43eb9a7ec94b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69605f9-025b-478e-8662-71fa80c2cc99",
   "metadata": {},
   "source": [
    "## The GPU Metrics Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59489a-2102-48dd-a949-9f41d1b8ed9d",
   "metadata": {},
   "source": [
    "As we have worked to develop the basics of Morpheus pipelines, we have been using `nvsmi.jsonlines`. But now that we are going to do meaningful work with it, let's take a closer look.\n",
    "\n",
    "`nvsmi.jsonlines` is known to contain mining behavior profiles. The dataset is in the `.jsonlines` format which means each new line represents an new JSON object. In order to parse this data, it must be ingested, split by lines into individual JSON objects, and parsed into cuDF dataframes. This will all be handled by Morpheus.\n",
    "\n",
    "The dataset contains NVIDIA GPU metrics at regular time intervals and was extracted by a [NetQ](https://www.nvidia.com/en-us/networking/ethernet-switching/netq/) agent and serialized into JSON. Each line in the dataset contains much of the same information that is returned by the `nvidia-smi` utility. For those unfamiliar, `nvidia-smi` is a command-line program to inspect how GPUs in a system are being utilized. If you were to run `nvidia-smi dmon` yourself, you would see output similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0377aa1d-87ff-4c43-b202-f5e58363f253",
   "metadata": {},
   "source": [
    "```sh\n",
    "$ nvidia-smi dmon\n",
    "# gpu   pwr gtemp mtemp    sm   mem   enc   dec  mclk  pclk\n",
    "# Idx     W     C     C     %     %     %     %   MHz   MHz\n",
    "    0    70    48     -     5     1     0     0  7000  1350\n",
    "    0    68    48     -    11     1     0     0  7000  1350\n",
    "    0    69    48     -     3     1     0     0  7000  1350\n",
    "    0   270    53     -    10     1     0     0  7000  1875\n",
    "    0   274    55     -    75    46     0     0  7000  1740\n",
    "    0   278    55     -    86    56     0     0  7000  1755\n",
    "    0   279    56     -    99    63     0     0  7000  1755\n",
    "    0   277    57     -    86    55     0     0  7000  1755\n",
    "    0   281    57     -    85    54     0     0  7000  1740\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54300c9c-d922-4db7-bd1c-4a83eeb2aa18",
   "metadata": {},
   "source": [
    "Each line in the output represents the GPU metrics at a single point in time. As the tool progresses the GPU begins to be utilized and you can see the `SM%` and `Mem%` increase as memory is loaded into the GPU and computations are performed.\n",
    "\n",
    "The model we will be using can ingest this information and determine whether or not the GPU is mining cryptocurrencies without needing additional information from the host machine.\n",
    "\n",
    "**Optional:** Feel free if you like to open a terminal and issue the `nvidia-smi dmon` command. Your output will be significantly different than the above on account of the fact that you are not currently utilizing the available GPU in this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0c96f-8494-4ea2-bbcc-dc12cbd220d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c96dff-6d77-491b-b493-47da1a7619ab",
   "metadata": {},
   "source": [
    "Before building out the pipeline, let's look briefly at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "357a3f44-dcf3-47e7-8368-200e9781f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1dcda74-1fb0-46cf-bbf0-97b0a0bfbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_json('nvsmi.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50d27ae1-23fd-4e87-a14c-c65d10eacf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 175)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e4e1bf4-2d92-4792-a322-50612fd6f899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nvidia_smi_log.timestamp                               object\n",
       "nvidia_smi_log.gpu.pci.tx_util                         object\n",
       "nvidia_smi_log.gpu.pci.rx_util                         object\n",
       "nvidia_smi_log.gpu.fb_memory_usage.used                object\n",
       "nvidia_smi_log.gpu.fb_memory_usage.free                object\n",
       "                                                    ...      \n",
       "nvidia_smi_log.gpu.utilization.decoder_util            object\n",
       "nvidia_smi_log.gpu.utilization.encoder_util            object\n",
       "nvidia_smi_log.gpu.uuid                                object\n",
       "nvidia_smi_log.gpu.vbios_version                       object\n",
       "timestamp                                      datetime64[ns]\n",
       "Length: 175, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2380613e-5780-4dde-8185-0e304a8896ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nvidia_smi_log.timestamp</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.tx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.rx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.total</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.gpu_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.memory_util</th>\n",
       "      <th>...</th>\n",
       "      <th>nvidia_smi_log.gpu.retired_pages.pending_retirement</th>\n",
       "      <th>nvidia_smi_log.gpu.serial</th>\n",
       "      <th>nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_max</th>\n",
       "      <th>nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_min</th>\n",
       "      <th>nvidia_smi_log.gpu.temperature.gpu_target_temperature</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.decoder_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.encoder_util</th>\n",
       "      <th>nvidia_smi_log.gpu.uuid</th>\n",
       "      <th>nvidia_smi_log.gpu.vbios_version</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Mar 12 09:46:00 2021</td>\n",
       "      <td>0 KB/s</td>\n",
       "      <td>0 KB/s</td>\n",
       "      <td>3909 MiB</td>\n",
       "      <td>12251 MiB</td>\n",
       "      <td>16384 MiB</td>\n",
       "      <td>7 MiB</td>\n",
       "      <td>16377 MiB</td>\n",
       "      <td>100 %</td>\n",
       "      <td>2 %</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 09:46:00.956650240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Mar 12 09:46:31 2021</td>\n",
       "      <td>0 KB/s</td>\n",
       "      <td>2000 KB/s</td>\n",
       "      <td>3909 MiB</td>\n",
       "      <td>12251 MiB</td>\n",
       "      <td>16384 MiB</td>\n",
       "      <td>7 MiB</td>\n",
       "      <td>16377 MiB</td>\n",
       "      <td>100 %</td>\n",
       "      <td>5 %</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 09:46:31.070379008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Mar 12 09:47:01 2021</td>\n",
       "      <td>1000 KB/s</td>\n",
       "      <td>2000 KB/s</td>\n",
       "      <td>3909 MiB</td>\n",
       "      <td>12251 MiB</td>\n",
       "      <td>16384 MiB</td>\n",
       "      <td>7 MiB</td>\n",
       "      <td>16377 MiB</td>\n",
       "      <td>100 %</td>\n",
       "      <td>5 %</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 09:47:01.904752128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Mar 12 09:47:32 2021</td>\n",
       "      <td>0 KB/s</td>\n",
       "      <td>2000 KB/s</td>\n",
       "      <td>3909 MiB</td>\n",
       "      <td>12251 MiB</td>\n",
       "      <td>16384 MiB</td>\n",
       "      <td>7 MiB</td>\n",
       "      <td>16377 MiB</td>\n",
       "      <td>100 %</td>\n",
       "      <td>6 %</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 09:47:32.742011904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Mar 12 09:48:02 2021</td>\n",
       "      <td>1000 KB/s</td>\n",
       "      <td>2000 KB/s</td>\n",
       "      <td>3909 MiB</td>\n",
       "      <td>12251 MiB</td>\n",
       "      <td>16384 MiB</td>\n",
       "      <td>7 MiB</td>\n",
       "      <td>16377 MiB</td>\n",
       "      <td>100 %</td>\n",
       "      <td>6 %</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 09:48:02.556625152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nvidia_smi_log.timestamp nvidia_smi_log.gpu.pci.tx_util  \\\n",
       "0  Fri Mar 12 09:46:00 2021                         0 KB/s   \n",
       "1  Fri Mar 12 09:46:31 2021                         0 KB/s   \n",
       "2  Fri Mar 12 09:47:01 2021                      1000 KB/s   \n",
       "3  Fri Mar 12 09:47:32 2021                         0 KB/s   \n",
       "4  Fri Mar 12 09:48:02 2021                      1000 KB/s   \n",
       "\n",
       "  nvidia_smi_log.gpu.pci.rx_util nvidia_smi_log.gpu.fb_memory_usage.used  \\\n",
       "0                         0 KB/s                                3909 MiB   \n",
       "1                      2000 KB/s                                3909 MiB   \n",
       "2                      2000 KB/s                                3909 MiB   \n",
       "3                      2000 KB/s                                3909 MiB   \n",
       "4                      2000 KB/s                                3909 MiB   \n",
       "\n",
       "  nvidia_smi_log.gpu.fb_memory_usage.free  \\\n",
       "0                               12251 MiB   \n",
       "1                               12251 MiB   \n",
       "2                               12251 MiB   \n",
       "3                               12251 MiB   \n",
       "4                               12251 MiB   \n",
       "\n",
       "  nvidia_smi_log.gpu.bar1_memory_usage.total  \\\n",
       "0                                  16384 MiB   \n",
       "1                                  16384 MiB   \n",
       "2                                  16384 MiB   \n",
       "3                                  16384 MiB   \n",
       "4                                  16384 MiB   \n",
       "\n",
       "  nvidia_smi_log.gpu.bar1_memory_usage.used  \\\n",
       "0                                     7 MiB   \n",
       "1                                     7 MiB   \n",
       "2                                     7 MiB   \n",
       "3                                     7 MiB   \n",
       "4                                     7 MiB   \n",
       "\n",
       "  nvidia_smi_log.gpu.bar1_memory_usage.free  \\\n",
       "0                                 16377 MiB   \n",
       "1                                 16377 MiB   \n",
       "2                                 16377 MiB   \n",
       "3                                 16377 MiB   \n",
       "4                                 16377 MiB   \n",
       "\n",
       "  nvidia_smi_log.gpu.utilization.gpu_util  \\\n",
       "0                                   100 %   \n",
       "1                                   100 %   \n",
       "2                                   100 %   \n",
       "3                                   100 %   \n",
       "4                                   100 %   \n",
       "\n",
       "  nvidia_smi_log.gpu.utilization.memory_util  ...  \\\n",
       "0                                        2 %  ...   \n",
       "1                                        5 %  ...   \n",
       "2                                        5 %  ...   \n",
       "3                                        6 %  ...   \n",
       "4                                        6 %  ...   \n",
       "\n",
       "  nvidia_smi_log.gpu.retired_pages.pending_retirement  \\\n",
       "0                                                 No    \n",
       "1                                                 No    \n",
       "2                                                 No    \n",
       "3                                                 No    \n",
       "4                                                 No    \n",
       "\n",
       "  nvidia_smi_log.gpu.serial  \\\n",
       "0              322917026071   \n",
       "1              322917026071   \n",
       "2              322917026071   \n",
       "3              322917026071   \n",
       "4              322917026071   \n",
       "\n",
       "  nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_max  \\\n",
       "0                                                N/A                 \n",
       "1                                                N/A                 \n",
       "2                                                N/A                 \n",
       "3                                                N/A                 \n",
       "4                                                N/A                 \n",
       "\n",
       "  nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_min  \\\n",
       "0                                                N/A                 \n",
       "1                                                N/A                 \n",
       "2                                                N/A                 \n",
       "3                                                N/A                 \n",
       "4                                                N/A                 \n",
       "\n",
       "  nvidia_smi_log.gpu.temperature.gpu_target_temperature  \\\n",
       "0                                                N/A      \n",
       "1                                                N/A      \n",
       "2                                                N/A      \n",
       "3                                                N/A      \n",
       "4                                                N/A      \n",
       "\n",
       "  nvidia_smi_log.gpu.utilization.decoder_util  \\\n",
       "0                                         0 %   \n",
       "1                                         0 %   \n",
       "2                                         0 %   \n",
       "3                                         0 %   \n",
       "4                                         0 %   \n",
       "\n",
       "  nvidia_smi_log.gpu.utilization.encoder_util  \\\n",
       "0                                         0 %   \n",
       "1                                         0 %   \n",
       "2                                         0 %   \n",
       "3                                         0 %   \n",
       "4                                         0 %   \n",
       "\n",
       "                    nvidia_smi_log.gpu.uuid nvidia_smi_log.gpu.vbios_version  \\\n",
       "0  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa                   88.00.4F.00.09   \n",
       "1  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa                   88.00.4F.00.09   \n",
       "2  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa                   88.00.4F.00.09   \n",
       "3  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa                   88.00.4F.00.09   \n",
       "4  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa                   88.00.4F.00.09   \n",
       "\n",
       "                      timestamp  \n",
       "0 2021-03-12 09:46:00.956650240  \n",
       "1 2021-03-12 09:46:31.070379008  \n",
       "2 2021-03-12 09:47:01.904752128  \n",
       "3 2021-03-12 09:47:32.742011904  \n",
       "4 2021-03-12 09:48:02.556625152  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8bfd5-dfcc-4b38-b616-d037ba3fa72d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10dcce-16b8-4b1f-af88-8dd535f21e5c",
   "metadata": {},
   "source": [
    "## Add Triton Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbe112-edf9-458d-aaa1-0431ea59adc0",
   "metadata": {},
   "source": [
    "Let's build inference into the pipeline that will use the `abp-nvsmi-xgb` XGBoost model, already loaded into Triton, as shown in the previous notebook.\n",
    "\n",
    "To begin, here is the pipeline we have build out so far which only performs no-op inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2a0bd-5846-4871-87a0-faae9658ee0b",
   "metadata": {},
   "source": [
    "```sh\n",
    "morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-identity \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137eaf7b-c5df-43e0-8ef2-df98b11474d3",
   "metadata": {},
   "source": [
    "Here we replace the `inf-identity` stage with `inf-triton`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b0b2b6-c0d2-4d66-bf97-309ae3d64fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "Usage: morpheus run pipeline-fil inf-triton [OPTIONS]\n",
      "Try 'morpheus run pipeline-fil inf-triton --help' for help.\n",
      "\n",
      "Error: Missing option '--model_name'.\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-triton \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d142926-66fe-4c55-a22d-4bf65b63565c",
   "metadata": {},
   "source": [
    "We can see that we are missing the `--model_name` option for the `inf-triton` stage. Let's look at the help message for this stage as recommended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67570683-a6b1-4386-92fc-887c6d59eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "Usage: morpheus run pipeline-fil inf-triton [OPTIONS]\n",
      "\n",
      "Options:\n",
      "  --model_name TEXT               Model name in Triton to send messages to\n",
      "                                  [required]\n",
      "  --server_url TEXT               Triton server URL (IP:Port)  [required]\n",
      "  --force_convert_inputs BOOLEAN  Instructs this stage to forcibly convert all\n",
      "                                  input types to match what Triton is\n",
      "                                  expecting. Even if this is set to `False`,\n",
      "                                  automatic conversion will be done only if\n",
      "                                  there would be no data loss (i.e. int32 ->\n",
      "                                  int64).  [default: False]\n",
      "  --use_shared_memory BOOLEAN     Whether or not to use CUDA Shared IPC Memory\n",
      "                                  for transferring data to Triton. Using CUDA\n",
      "                                  IPC reduces network transfer time but\n",
      "                                  requires that Morpheus and Triton are\n",
      "                                  located on the same machine  [default:\n",
      "                                  False]\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil inf-triton --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ae408-dc84-442a-b14f-0f227436de60",
   "metadata": {},
   "source": [
    "The message indicates that there are two required options we need to provide: `--model_name` and `--server_url`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe936f-29b7-48b4-86b2-bd86338e5e9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043ae2c-9e9f-40eb-9a41-e66b8943e43d",
   "metadata": {},
   "source": [
    "## Exercise Part 1: Send Data to `abp-nvsmi-xgb` in Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29d8db-f5e5-4aef-a9c5-533834436539",
   "metadata": {},
   "source": [
    "Fix the `inf-triton` stage in the pipeline below to send data for inference to the `abp-nvsmi-xgb` model, already loaded for you into the Triton server running at `triton:8001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a7fadd-bb39-4f9a-a42a-a940c71fbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-triton --model_name=\"abp-nvsmi-xgb\" --server_url=\"triton:8001\" \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34bfab-6a6c-4fd8-a90b-300b6169a43a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637b655-2fa2-41d9-a476-4b00259b14b6",
   "metadata": {},
   "source": [
    "If you get stuck or need help, click the `...` below to display the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a37435-ef85-41fa-9af8-f7657710aad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-triton --model_name=\"abp-nvsmi-xgb\" --server_url=\"triton:8001\" \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0af87-07f7-4f6c-8354-0f3fb97b6099",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2458edf-23d6-4e2c-af2d-9ef9b9adb5ff",
   "metadata": {},
   "source": [
    "### Check for Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf7be4-d16e-439d-a9e2-5fe09f2f08e9",
   "metadata": {},
   "source": [
    "Assuming the pipeline has run without errors, we would like to see the results of the inference. Let's take a quick look at the first row of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d0353c-dca4-4b10-b5e1-a15f12cd7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f221a8-cc37-4a6e-816b-6811c1b26f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_json('output.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ec8176-ba00-4192-a0f2-59988ddee462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nvidia_smi_log.timestamp</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.tx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.rx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.total</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.gpu_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.memory_util</th>\n",
       "      <th>...</th>\n",
       "      <th>nvidia_smi_log.gpu.retired_pages.pending_retirement</th>\n",
       "      <th>nvidia_smi_log.gpu.serial</th>\n",
       "      <th>nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_max</th>\n",
       "      <th>nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_min</th>\n",
       "      <th>nvidia_smi_log.gpu.temperature.gpu_target_temperature</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.decoder_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.encoder_util</th>\n",
       "      <th>nvidia_smi_log.gpu.uuid</th>\n",
       "      <th>nvidia_smi_log.gpu.vbios_version</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Mar 12 09:46:00 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3909</td>\n",
       "      <td>12251</td>\n",
       "      <td>16384</td>\n",
       "      <td>7</td>\n",
       "      <td>16377</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 09:46:00.956650496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nvidia_smi_log.timestamp  nvidia_smi_log.gpu.pci.tx_util  \\\n",
       "0  Fri Mar 12 09:46:00 2021                               0   \n",
       "\n",
       "   nvidia_smi_log.gpu.pci.rx_util  nvidia_smi_log.gpu.fb_memory_usage.used  \\\n",
       "0                               0                                     3909   \n",
       "\n",
       "   nvidia_smi_log.gpu.fb_memory_usage.free  \\\n",
       "0                                    12251   \n",
       "\n",
       "   nvidia_smi_log.gpu.bar1_memory_usage.total  \\\n",
       "0                                       16384   \n",
       "\n",
       "   nvidia_smi_log.gpu.bar1_memory_usage.used  \\\n",
       "0                                          7   \n",
       "\n",
       "   nvidia_smi_log.gpu.bar1_memory_usage.free  \\\n",
       "0                                      16377   \n",
       "\n",
       "   nvidia_smi_log.gpu.utilization.gpu_util  \\\n",
       "0                                      100   \n",
       "\n",
       "   nvidia_smi_log.gpu.utilization.memory_util  ...  \\\n",
       "0                                           2  ...   \n",
       "\n",
       "   nvidia_smi_log.gpu.retired_pages.pending_retirement  \\\n",
       "0                                                 No     \n",
       "\n",
       "   nvidia_smi_log.gpu.serial  \\\n",
       "0               322917026071   \n",
       "\n",
       "   nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_max  \\\n",
       "0                                                N/A                  \n",
       "\n",
       "   nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_min  \\\n",
       "0                                                N/A                  \n",
       "\n",
       "   nvidia_smi_log.gpu.temperature.gpu_target_temperature  \\\n",
       "0                                                N/A       \n",
       "\n",
       "   nvidia_smi_log.gpu.utilization.decoder_util  \\\n",
       "0                                          0 %   \n",
       "\n",
       "   nvidia_smi_log.gpu.utilization.encoder_util  \\\n",
       "0                                          0 %   \n",
       "\n",
       "                    nvidia_smi_log.gpu.uuid  nvidia_smi_log.gpu.vbios_version  \\\n",
       "0  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa                    88.00.4F.00.09   \n",
       "\n",
       "                      timestamp  \n",
       "0 2021-03-12 09:46:00.956650496  \n",
       "\n",
       "[1 rows x 175 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d5e00-d2f9-4502-80e3-952fe59e8c7b",
   "metadata": {},
   "source": [
    "Looking at the output, we do not see any indication that inference has been performed. The reason is simple, we need to explicitly add the results by adding an `add-class` stage to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba4ec8b9-e510-4e03-8869-9ac18e4dd73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4. The following stages must come after an inference stage: `add-class`, `filter`, `gen-viz`\n",
      "  add-class     Add detected classifications to each message\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil --help | grep 'add-class'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d421c116-742b-4fa4-b468-afbee4ccb031",
   "metadata": {},
   "source": [
    "We can see that `add-class` will add detected classifications to each message, and that the `add-class` stage needs to come after we perform inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d3911-95be-42bc-996b-03e3a89e7a7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70429967-6a66-4d83-8b85-b612b7f18242",
   "metadata": {},
   "source": [
    "## Exercise Part 2: Add Inference Results to the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154575f-2f26-42a9-a098-38624c721476",
   "metadata": {},
   "source": [
    "Fix the pipeline below to add classification labels to each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c701b2-13c8-479d-9c5d-34aab6da42f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConfiguring Pipeline via CLI\u001b[0m\n",
      "\u001b[31mStarting pipeline via CLI... Ctrl+C to Quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-triton --model_name=\"abp-nvsmi-xgb\" --server_url=\"triton:8001\" --force_convert_inputs=True \\\n",
    "  add-class \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14505ab8-ad52-47e8-b43e-b51eb2fd5031",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7640f-70f4-41ce-ac87-afa062871035",
   "metadata": {},
   "source": [
    "If you get stuck or need help, click the `...` below to display the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8cc7f-142d-46aa-a034-4f3a4e9c3d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!morpheus run pipeline-fil \\\n",
    "  from-file --filename=nvsmi.jsonlines \\\n",
    "  deserialize \\\n",
    "  preprocess \\\n",
    "  inf-triton --model_name=\"abp-nvsmi-xgb\" --server_url=\"triton:8001\" --force_convert_inputs=True \\\n",
    "  add-class \\\n",
    "  serialize \\\n",
    "  to-file --filename=output.jsonlines --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5e6c5-031c-4f59-90ec-58abfe15794c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c2544-ab16-4a3e-9353-371663222cc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a453fb-0a91-455b-bfe0-799f17a9b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06199db5-5c27-48b3-b58e-6894360f3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_json('output.jsonlines', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aef3bc4a-3324-41f0-8e13-d051afe0113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nvidia_smi_log.timestamp                               object\n",
       "nvidia_smi_log.gpu.pci.tx_util                          int64\n",
       "nvidia_smi_log.gpu.pci.rx_util                          int64\n",
       "nvidia_smi_log.gpu.fb_memory_usage.used                 int64\n",
       "nvidia_smi_log.gpu.fb_memory_usage.free                 int64\n",
       "                                                    ...      \n",
       "nvidia_smi_log.gpu.utilization.encoder_util            object\n",
       "nvidia_smi_log.gpu.uuid                                object\n",
       "nvidia_smi_log.gpu.vbios_version                       object\n",
       "timestamp                                      datetime64[ns]\n",
       "mining                                                  int64\n",
       "Length: 176, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9c0ea-5e7c-4810-8340-5f42650813b8",
   "metadata": {},
   "source": [
    "We can see that an `int64` `mining` column has been added to each row of the data. The `add-class` stage will set the value of this field to `1` for each row that was identified during inference as being involved in cryptocurrency mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68c1e748-fcc5-4b97-a116-5e4ea1dc5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "mining = results[results['mining'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7423ff2f-782b-4a1a-a98e-06905c9c7313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 176)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mining.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6289f4f-ce58-4748-9eca-7fe0965a1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nvidia_smi_log.timestamp</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.tx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.pci.rx_util</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.fb_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.total</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.used</th>\n",
       "      <th>nvidia_smi_log.gpu.bar1_memory_usage.free</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.gpu_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.memory_util</th>\n",
       "      <th>...</th>\n",
       "      <th>nvidia_smi_log.gpu.serial</th>\n",
       "      <th>nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_max</th>\n",
       "      <th>nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_min</th>\n",
       "      <th>nvidia_smi_log.gpu.temperature.gpu_target_temperature</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.decoder_util</th>\n",
       "      <th>nvidia_smi_log.gpu.utilization.encoder_util</th>\n",
       "      <th>nvidia_smi_log.gpu.uuid</th>\n",
       "      <th>nvidia_smi_log.gpu.vbios_version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Fri Mar 12 18:58:29 2021</td>\n",
       "      <td>72000</td>\n",
       "      <td>103000</td>\n",
       "      <td>7264</td>\n",
       "      <td>8896</td>\n",
       "      <td>16384</td>\n",
       "      <td>11</td>\n",
       "      <td>16373</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 18:58:29.392179968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Fri Mar 12 18:59:01 2021</td>\n",
       "      <td>77000</td>\n",
       "      <td>94000</td>\n",
       "      <td>7264</td>\n",
       "      <td>8896</td>\n",
       "      <td>16384</td>\n",
       "      <td>11</td>\n",
       "      <td>16373</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 18:59:01.259411200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Fri Mar 12 18:59:32 2021</td>\n",
       "      <td>73000</td>\n",
       "      <td>86000</td>\n",
       "      <td>7264</td>\n",
       "      <td>8896</td>\n",
       "      <td>16384</td>\n",
       "      <td>11</td>\n",
       "      <td>16373</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 18:59:32.822284544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Fri Mar 12 19:00:03 2021</td>\n",
       "      <td>49000</td>\n",
       "      <td>101000</td>\n",
       "      <td>7264</td>\n",
       "      <td>8896</td>\n",
       "      <td>16384</td>\n",
       "      <td>11</td>\n",
       "      <td>16373</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 19:00:03.437993984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>Fri Mar 12 19:00:35 2021</td>\n",
       "      <td>58000</td>\n",
       "      <td>83000</td>\n",
       "      <td>7264</td>\n",
       "      <td>8896</td>\n",
       "      <td>16384</td>\n",
       "      <td>11</td>\n",
       "      <td>16373</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>322917026071</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0 %</td>\n",
       "      <td>0 %</td>\n",
       "      <td>GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa</td>\n",
       "      <td>88.00.4F.00.09</td>\n",
       "      <td>2021-03-12 19:00:35.062054144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nvidia_smi_log.timestamp  nvidia_smi_log.gpu.pci.tx_util  \\\n",
       "1054  Fri Mar 12 18:58:29 2021                           72000   \n",
       "1055  Fri Mar 12 18:59:01 2021                           77000   \n",
       "1056  Fri Mar 12 18:59:32 2021                           73000   \n",
       "1057  Fri Mar 12 19:00:03 2021                           49000   \n",
       "1058  Fri Mar 12 19:00:35 2021                           58000   \n",
       "\n",
       "      nvidia_smi_log.gpu.pci.rx_util  nvidia_smi_log.gpu.fb_memory_usage.used  \\\n",
       "1054                          103000                                     7264   \n",
       "1055                           94000                                     7264   \n",
       "1056                           86000                                     7264   \n",
       "1057                          101000                                     7264   \n",
       "1058                           83000                                     7264   \n",
       "\n",
       "      nvidia_smi_log.gpu.fb_memory_usage.free  \\\n",
       "1054                                     8896   \n",
       "1055                                     8896   \n",
       "1056                                     8896   \n",
       "1057                                     8896   \n",
       "1058                                     8896   \n",
       "\n",
       "      nvidia_smi_log.gpu.bar1_memory_usage.total  \\\n",
       "1054                                       16384   \n",
       "1055                                       16384   \n",
       "1056                                       16384   \n",
       "1057                                       16384   \n",
       "1058                                       16384   \n",
       "\n",
       "      nvidia_smi_log.gpu.bar1_memory_usage.used  \\\n",
       "1054                                         11   \n",
       "1055                                         11   \n",
       "1056                                         11   \n",
       "1057                                         11   \n",
       "1058                                         11   \n",
       "\n",
       "      nvidia_smi_log.gpu.bar1_memory_usage.free  \\\n",
       "1054                                      16373   \n",
       "1055                                      16373   \n",
       "1056                                      16373   \n",
       "1057                                      16373   \n",
       "1058                                      16373   \n",
       "\n",
       "      nvidia_smi_log.gpu.utilization.gpu_util  \\\n",
       "1054                                      100   \n",
       "1055                                      100   \n",
       "1056                                      100   \n",
       "1057                                      100   \n",
       "1058                                      100   \n",
       "\n",
       "      nvidia_smi_log.gpu.utilization.memory_util  ...  \\\n",
       "1054                                          17  ...   \n",
       "1055                                          18  ...   \n",
       "1056                                          17  ...   \n",
       "1057                                          19  ...   \n",
       "1058                                          18  ...   \n",
       "\n",
       "      nvidia_smi_log.gpu.serial  \\\n",
       "1054               322917026071   \n",
       "1055               322917026071   \n",
       "1056               322917026071   \n",
       "1057               322917026071   \n",
       "1058               322917026071   \n",
       "\n",
       "      nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_max  \\\n",
       "1054                                                N/A                  \n",
       "1055                                                N/A                  \n",
       "1056                                                N/A                  \n",
       "1057                                                N/A                  \n",
       "1058                                                N/A                  \n",
       "\n",
       "      nvidia_smi_log.gpu.supported_gpu_target_temp.gpu_target_temp_min  \\\n",
       "1054                                                N/A                  \n",
       "1055                                                N/A                  \n",
       "1056                                                N/A                  \n",
       "1057                                                N/A                  \n",
       "1058                                                N/A                  \n",
       "\n",
       "      nvidia_smi_log.gpu.temperature.gpu_target_temperature  \\\n",
       "1054                                                N/A       \n",
       "1055                                                N/A       \n",
       "1056                                                N/A       \n",
       "1057                                                N/A       \n",
       "1058                                                N/A       \n",
       "\n",
       "      nvidia_smi_log.gpu.utilization.decoder_util  \\\n",
       "1054                                          0 %   \n",
       "1055                                          0 %   \n",
       "1056                                          0 %   \n",
       "1057                                          0 %   \n",
       "1058                                          0 %   \n",
       "\n",
       "      nvidia_smi_log.gpu.utilization.encoder_util  \\\n",
       "1054                                          0 %   \n",
       "1055                                          0 %   \n",
       "1056                                          0 %   \n",
       "1057                                          0 %   \n",
       "1058                                          0 %   \n",
       "\n",
       "                       nvidia_smi_log.gpu.uuid  \\\n",
       "1054  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa   \n",
       "1055  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa   \n",
       "1056  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa   \n",
       "1057  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa   \n",
       "1058  GPU-98f29bfe-f021-7214-6f7a-b70c56ecf2aa   \n",
       "\n",
       "      nvidia_smi_log.gpu.vbios_version                     timestamp  mining  \n",
       "1054                    88.00.4F.00.09 2021-03-12 18:58:29.392179968       1  \n",
       "1055                    88.00.4F.00.09 2021-03-12 18:59:01.259411200       1  \n",
       "1056                    88.00.4F.00.09 2021-03-12 18:59:32.822284544       1  \n",
       "1057                    88.00.4F.00.09 2021-03-12 19:00:03.437993984       1  \n",
       "1058                    88.00.4F.00.09 2021-03-12 19:00:35.062054144       1  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mining.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddc705-e6a2-4091-b0ca-f6e4168be384",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db5382-5681-4f1a-850c-4eee66ff3c95",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433cc33-8929-446a-9bf7-5c0ccce9824a",
   "metadata": {},
   "source": [
    "In the next section we will begin to learn about a second Morpheus pipeline, `pipeline-nlp` first with a very high-level introduction to natural language processing.\n",
    "\n",
    "Please continue to the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
